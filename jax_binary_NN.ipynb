{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# JAX Binary Neural Network\n",
        "In this notebook, we implement a binary neural network using the JAX framework. Neural networks have proven to be powerful models for solving a wide range of real-world tasks. However, as models grow in complexity, their increasing number of parameters makes them significantly more expensive to store and run, especially on memory-constrained hardware like RAM or GPUs.\n",
        "\n",
        "A popular approach to reduce model size is quantization, which aims to decrease the bit-width of each parameter. Standard methods often quantize only the model's weights (e.g., to 8-bit integers) while leaving activations in floating-point, which still leaves room for further optimization. This raises an interesting question: what if we take this to the extreme? Is it possible to train a functional neural network where both the weights and the activations are binary (i.e., having a value of either -1 or 1)?\n",
        "\n",
        "This notebook explores this question by building a simple MLP architecture for the MNIST dataset. Simply converting a pre-trained, full-precision MLP to a binary one is guaranteed to fail due to the massive loss of information. Instead, we train the network in its binary form directly. To make this possible, we introduce two key modifications to the standard training process:\n",
        "1. **Binarization**: We constrain all inputs, weights, and activations to values of either -1 or 1.\n",
        "2. **Gradient Approximation**: Since the binarization function is non-differentiable, we leverage the Straight-Through Estimator (STE) to approximate gradients, enabling the use of standard backpropagation.\n",
        "\n",
        "Beyond academic curiosity, binary neural networks have significant practical applications. For instance, they are ideal for deployment on resource-constrained IoT devices. By running a model directly on a device, we can enable on-device processing, eliminating the latency and cost of API calls to a remote server. This creates opportunities for many new intelligent, edge-computing applications.\n",
        "\n",
        "Furthermore, binary networks are exceptionally efficient. The multiplication of two values from the set {-1, 1} is equivalent to a logical XNOR operation. This allows the expensive floating-point multiplications found in standard networks to be replaced with highly efficient bitwise operations, dramatically accelerating inference speed.\n"
      ],
      "metadata": {
        "id": "20gDFA8sHCIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library\n",
        "\n",
        "We use a few key libraries to build and train our network:\n",
        "*   **JAX** and **NumPy**: For high-performance numerical computation and array manipulation.\n",
        "*   **Optax**: A flexible optimization library built for JAX, which we use to implement our Adam optimizer.\n",
        "*   **Keras**: We use `keras.datasets` for a convenient way to download and load the MNIST dataset.\n",
        "*   **`jax.lax.stop_gradient`**: This function is the cornerstone of our implementation. It allows us to implement the Straight-Through Estimator by selectively blocking gradients during the backward pass, which is essential for training our non-differentiable binary network."
      ],
      "metadata": {
        "id": "7GtSlCSoOvUQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_jgOgMV_HXEC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad\n",
        "from jax.lax import stop_gradient\n",
        "import optax\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing\n",
        "\n",
        "We preprocess the input data to align with the binary nature of our network. The goal is to convert each input image into a vector of -1s and 1s.\n",
        "\n",
        "This is done in three steps:\n",
        "1.  **Normalization**: We first scale the raw pixel values from their original `[0, 255]` range to a new range of `[-1, 1]`.\n",
        "2.  **Binarization**: We then discretize these normalized values. Any pixel value less than 0 is set to -1, and any value greater than or equal to 0 is set to 1. This effectively converts the grayscale images into stark black-and-white versions.\n",
        "3.  **Reshaping**: Finally, we flatten each 28x28 image into a single 784-element vector, preparing the data to be fed into the input layer of our MLP."
      ],
      "metadata": {
        "id": "vu5Q6L5fPFif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(len(x_train), -1)/255*2-1\n",
        "x_test = x_test.reshape(len(x_test), -1)/255*2-1\n",
        "\n",
        "x_train = (x_train > 0)*2-1\n",
        "x_test = (x_test > 0)*2-1"
      ],
      "metadata": {
        "id": "XpQTqaFrQnKL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[2].reshape(28,28), cmap = 'gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ydntR-8mPdVS",
        "outputId": "aa312f93-2aeb-4356-c27f-82aea33763d6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x79f07f1f0610>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGLRJREFUeJzt3X9M1Pcdx/HX+YOrtnAUEY6raFFbTWplmVNGXF0XieIWU9Q/XNc/7GJstGczde0Wl6jttoTNJs3SxbT7S9Os2s5kaOofJoqC2YY2tRpj1hFhbGAEXE34HqKggc/+YL31FETgjvfd8Xwkn6TcfeHefPnKs8d9+eJzzjkBADDGJlgPAAAYnwgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwMcl6gHv19fXp2rVryszMlM/nsx4HADBMzjl1dnYqFAppwoTBn+ckXYCuXbumwsJC6zEAAKPU0tKiGTNmDHp/0v0ILjMz03oEAEAcDPX9PGEB2rdvn5588kk98sgjKikp0aeffvpQ78eP3QAgPQz1/TwhAfr444+1Y8cO7dmzR59//rmKi4u1cuVKXb9+PREPBwBIRS4BlixZ4sLhcPTt3t5eFwqFXGVl5ZDv63mek8RisVisFF+e5z3w+33cnwHduXNH58+fV1lZWfS2CRMmqKysTHV1dfdt39PTo0gkErMAAOkv7gH68ssv1dvbq/z8/Jjb8/Pz1dbWdt/2lZWVCgQC0cUZcAAwPpifBbdz5055nhddLS0t1iMBAMZA3H8PKDc3VxMnTlR7e3vM7e3t7QoGg/dt7/f75ff74z0GACDJxf0ZUEZGhhYtWqTq6urobX19faqurlZpaWm8Hw4AkKISciWEHTt2aMOGDfrWt76lJUuW6He/+526urr04x//OBEPBwBIQQkJ0Pr16/Wf//xHu3fvVltbm77xjW/o+PHj952YAAAYv3zOOWc9xNdFIhEFAgHrMQAAo+R5nrKysga93/wsOADA+ESAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYmGQ9AAAkmnNuRO/n8/niPAm+jmdAAAATBAgAYCLuAXrzzTfl8/li1vz58+P9MACAFJeQ14CeeeYZnTx58v8PMomXmgAAsRJShkmTJikYDCbiQwMA0kRCXgO6cuWKQqGQZs+erZdeeknNzc2DbtvT06NIJBKzAADpL+4BKikp0YEDB3T8+HG99957ampq0nPPPafOzs4Bt6+srFQgEIiuwsLCeI8EAEhCPjfSE+QfUkdHh2bNmqV33nlHGzduvO/+np4e9fT0RN+ORCJECEBc8XtANjzPU1ZW1qD3J/zsgOzsbD399NNqaGgY8H6/3y+/35/oMQAASSbhvwd08+ZNNTY2qqCgINEPBQBIIXEP0Ouvv67a2lr961//0t/+9jetWbNGEydO1IsvvhjvhwIApLC4/wju6tWrevHFF3Xjxg1Nnz5d3/nOd3T27FlNnz493g8FAEhhCT8JYbgikYgCgYD1GADSCCch2BjqJASuBQcAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmEj4H6TDyI3kAopcPBHpLsmun4xR4BkQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHA17DHCFXwBIBbPgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE1yMFICZsbpIr8/nG5PHwfDwDAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYGHaAzpw5o9WrVysUCsnn8+nIkSMx9zvntHv3bhUUFGjKlCkqKyvTlStX4jUvACBNDDtAXV1dKi4u1r59+wa8f+/evXr33Xf1/vvv69y5c3r00Ue1cuVKdXd3j3pYAEAacaMgyVVVVUXf7uvrc8Fg0L399tvR2zo6Opzf73eHDh16qI/peZ6TlHZrrFh/nizWcBb/LtJ7eZ73wK9LXF8DampqUltbm8rKyqK3BQIBlZSUqK6ubsD36enpUSQSiVkAgPQX1wC1tbVJkvLz82Nuz8/Pj953r8rKSgUCgegqLCyM50gAgCRlfhbczp075XledLW0tFiPBAAYA3ENUDAYlCS1t7fH3N7e3h69715+v19ZWVkxCwCQ/uIaoKKiIgWDQVVXV0dvi0QiOnfunEpLS+P5UACAFDdpuO9w8+ZNNTQ0RN9uamrSxYsXlZOTo5kzZ2rbtm369a9/raeeekpFRUXatWuXQqGQKioq4jk3ACDVDfd0xtOnTw94ut2GDRucc/2nYu/atcvl5+c7v9/vli9f7urr6x/643Ma9uhYf54s1nAW/y7Sew11Grbvf1+cpBGJRBQIBKzHiLux2s0+n29MHgeIB/5dpDfP8x74ur75WXAAgPGJAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJob994DAFXyBgSTZhfWRAngGBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GKkAO6TzBcW5SK96YNnQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACS5GCnxNMl+EE0g3PAMCAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExwMdIkxoUx8XU+n896hAfieMVw8QwIAGCCAAEATAw7QGfOnNHq1asVCoXk8/l05MiRmPtffvll+Xy+mFVeXh6veQEAaWLYAerq6lJxcbH27ds36Dbl5eVqbW2NrkOHDo1qSABA+hn2SQirVq3SqlWrHriN3+9XMBgc8VAAgPSXkNeAampqlJeXp3nz5mnLli26cePGoNv29PQoEonELABA+ot7gMrLy/XBBx+ourpav/3tb1VbW6tVq1apt7d3wO0rKysVCASiq7CwMN4jAQCSkM+N4uR9n8+nqqoqVVRUDLrNP//5T82ZM0cnT57U8uXL77u/p6dHPT090bcjkUjSR4jfd4AFfg+oX7LvB/yf53nKysoa9P6En4Y9e/Zs5ebmqqGhYcD7/X6/srKyYhYAIP0lPEBXr17VjRs3VFBQkOiHAgCkkGGfBXfz5s2YZzNNTU26ePGicnJylJOTo7feekvr1q1TMBhUY2Ojfvazn2nu3LlauXJlXAcHAKS2Yb8GVFNTo+9973v33b5hwwa99957qqio0IULF9TR0aFQKKQVK1boV7/6lfLz8x/q40ciEQUCgeGMNOZ4DQgWkv21D14Dwr2Geg1oVCchJEIqBGisJNmXxgzfcFIDAcK9zE9CAABgIAQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADAx7L8HhLHDVX9hhSuxYyzwDAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHFSAGY4YK74xvPgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATwwpQZWWlFi9erMzMTOXl5amiokL19fUx23R3dyscDmvatGl67LHHtG7dOrW3t8d1aABA6htWgGpraxUOh3X27FmdOHFCd+/e1YoVK9TV1RXdZvv27frkk090+PBh1dbW6tq1a1q7dm3cBwcApDg3CtevX3eSXG1trXPOuY6ODjd58mR3+PDh6DZffPGFk+Tq6uoe6mN6nucksVgswzVWrD9PVmKX53kP/PqP6jUgz/MkSTk5OZKk8+fP6+7duyorK4tuM3/+fM2cOVN1dXUDfoyenh5FIpGYBQBIfyMOUF9fn7Zt26alS5dqwYIFkqS2tjZlZGQoOzs7Ztv8/Hy1tbUN+HEqKysVCASiq7CwcKQjAQBSyIgDFA6HdfnyZX300UejGmDnzp3yPC+6WlpaRvXxAACpYdJI3mnr1q06duyYzpw5oxkzZkRvDwaDunPnjjo6OmKeBbW3tysYDA74sfx+v/x+/0jGAACksGE9A3LOaevWraqqqtKpU6dUVFQUc/+iRYs0efJkVVdXR2+rr69Xc3OzSktL4zMxACAtDOsZUDgc1sGDB3X06FFlZmZGX9cJBAKaMmWKAoGANm7cqB07dignJ0dZWVl67bXXVFpaqm9/+9sJ+QQAACkqHqdM7t+/P7rN7du33auvvuoef/xxN3XqVLdmzRrX2tr60I/Badgslv0aK9afJyuxa6jTsH3/OwiSRiQSUSAQsB4DGNfG6tuCz+cbk8eBDc/zlJWVNej9XAsOAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJkb0F1EBIB5GctVtrqCdPngGBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwMcl6AADJx+fzDft9nHMJmATpjGdAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJLkYKIC5GcgFTjG88AwIAmCBAAAATwwpQZWWlFi9erMzMTOXl5amiokL19fUx2zz//PPy+Xwxa/PmzXEdGgCQ+oYVoNraWoXDYZ09e1YnTpzQ3bt3tWLFCnV1dcVst2nTJrW2tkbX3r174zo0ACD1DeskhOPHj8e8feDAAeXl5en8+fNatmxZ9PapU6cqGAzGZ0IAQFoa1WtAnudJknJycmJu//DDD5Wbm6sFCxZo586dunXr1qAfo6enR5FIJGYBAMYBN0K9vb3uBz/4gVu6dGnM7X/4wx/c8ePH3aVLl9wf//hH98QTT7g1a9YM+nH27NnjJLFYLBYrzZbneQ/syIgDtHnzZjdr1izX0tLywO2qq6udJNfQ0DDg/d3d3c7zvOhqaWkx32ksFovFGv0aKkAj+kXUrVu36tixYzpz5oxmzJjxwG1LSkokSQ0NDZozZ8599/v9fvn9/pGMAQBIYcMKkHNOr732mqqqqlRTU6OioqIh3+fixYuSpIKCghENCABIT8MKUDgc1sGDB3X06FFlZmaqra1NkhQIBDRlyhQ1Njbq4MGD+v73v69p06bp0qVL2r59u5YtW6aFCxcm5BMAAKSo4bzuo0F+zrd//37nnHPNzc1u2bJlLicnx/n9fjd37lz3xhtvDPlzwK/zPM/855YsFovFGv0a6nu/739hSRqRSESBQMB6DADAKHmep6ysrEHv51pwAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATSRcg55z1CACAOBjq+3nSBaizs9N6BABAHAz1/dznkuwpR19fn65du6bMzEz5fL6Y+yKRiAoLC9XS0qKsrCyjCe2xH/qxH/qxH/qxH/olw35wzqmzs1OhUEgTJgz+PGfSGM70UCZMmKAZM2Y8cJusrKxxfYB9hf3Qj/3Qj/3Qj/3Qz3o/BAKBIbdJuh/BAQDGBwIEADCRUgHy+/3as2eP/H6/9Sim2A/92A/92A/92A/9Umk/JN1JCACA8SGlngEBANIHAQIAmCBAAAATBAgAYCJlArRv3z49+eSTeuSRR1RSUqJPP/3UeqQx9+abb8rn88Ws+fPnW4+VcGfOnNHq1asVCoXk8/l05MiRmPudc9q9e7cKCgo0ZcoUlZWV6cqVKzbDJtBQ++Hll1++7/goLy+3GTZBKisrtXjxYmVmZiovL08VFRWqr6+P2aa7u1vhcFjTpk3TY489pnXr1qm9vd1o4sR4mP3w/PPP33c8bN682WjigaVEgD7++GPt2LFDe/bs0eeff67i4mKtXLlS169ftx5tzD3zzDNqbW2Nrr/85S/WIyVcV1eXiouLtW/fvgHv37t3r9599129//77OnfunB599FGtXLlS3d3dYzxpYg21HySpvLw85vg4dOjQGE6YeLW1tQqHwzp79qxOnDihu3fvasWKFerq6opus337dn3yySc6fPiwamtrde3aNa1du9Zw6vh7mP0gSZs2bYo5Hvbu3Ws08SBcCliyZIkLh8PRt3t7e10oFHKVlZWGU429PXv2uOLiYusxTElyVVVV0bf7+vpcMBh0b7/9dvS2jo4O5/f73aFDhwwmHBv37gfnnNuwYYN74YUXTOaxcv36dSfJ1dbWOuf6v/aTJ092hw8fjm7zxRdfOEmurq7OasyEu3c/OOfcd7/7XfeTn/zEbqiHkPTPgO7cuaPz58+rrKwsetuECRNUVlamuro6w8lsXLlyRaFQSLNnz9ZLL72k5uZm65FMNTU1qa2tLeb4CAQCKikpGZfHR01NjfLy8jRv3jxt2bJFN27csB4poTzPkyTl5ORIks6fP6+7d+/GHA/z58/XzJkz0/p4uHc/fOXDDz9Ubm6uFixYoJ07d+rWrVsW4w0q6S5Geq8vv/xSvb29ys/Pj7k9Pz9f//jHP4ymslFSUqIDBw5o3rx5am1t1VtvvaXnnntOly9fVmZmpvV4Jtra2iRpwOPjq/vGi/Lycq1du1ZFRUVqbGzUL37xC61atUp1dXWaOHGi9Xhx19fXp23btmnp0qVasGCBpP7jISMjQ9nZ2THbpvPxMNB+kKQf/ehHmjVrlkKhkC5duqSf//znqq+v15///GfDaWMlfYDwf6tWrYr+98KFC1VSUqJZs2bpT3/6kzZu3Gg4GZLBD3/4w+h/P/vss1q4cKHmzJmjmpoaLV++3HCyxAiHw7p8+fK4eB30QQbbD6+88kr0v5999lkVFBRo+fLlamxs1Jw5c8Z6zAEl/Y/gcnNzNXHixPvOYmlvb1cwGDSaKjlkZ2fr6aefVkNDg/UoZr46Bjg+7jd79mzl5uam5fGxdetWHTt2TKdPn4758y3BYFB37txRR0dHzPbpejwMth8GUlJSIklJdTwkfYAyMjK0aNEiVVdXR2/r6+tTdXW1SktLDSezd/PmTTU2NqqgoMB6FDNFRUUKBoMxx0ckEtG5c+fG/fFx9epV3bhxI62OD+ectm7dqqqqKp06dUpFRUUx9y9atEiTJ0+OOR7q6+vV3NycVsfDUPthIBcvXpSk5DoerM+CeBgfffSR8/v97sCBA+7vf/+7e+WVV1x2drZra2uzHm1M/fSnP3U1NTWuqanJ/fWvf3VlZWUuNzfXXb9+3Xq0hOrs7HQXLlxwFy5ccJLcO++84y5cuOD+/e9/O+ec+81vfuOys7Pd0aNH3aVLl9wLL7zgioqK3O3bt40nj68H7YfOzk73+uuvu7q6OtfU1OROnjzpvvnNb7qnnnrKdXd3W48eN1u2bHGBQMDV1NS41tbW6Lp161Z0m82bN7uZM2e6U6dOuc8++8yVlpa60tJSw6njb6j90NDQ4H75y1+6zz77zDU1NbmjR4+62bNnu2XLlhlPHislAuScc7///e/dzJkzXUZGhluyZIk7e/as9Uhjbv369a6goMBlZGS4J554wq1fv941NDRYj5Vwp0+fdpLuWxs2bHDO9Z+KvWvXLpefn+/8fr9bvny5q6+vtx06AR60H27duuVWrFjhpk+f7iZPnuxmzZrlNm3alHb/kzbQ5y/J7d+/P7rN7du33auvvuoef/xxN3XqVLdmzRrX2tpqN3QCDLUfmpub3bJly1xOTo7z+/1u7ty57o033nCe59kOfg/+HAMAwETSvwYEAEhPBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJ/wLwnPPqatMbhAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Binary Layer\n",
        "\n",
        "Our objective is to create a binary equivalent of a standard linear layer. This layer will operate exclusively with binary weights and produce binary outputs (vectors of -1s and 1s).\n",
        "\n",
        "The primary challenge is that the binarization process (a step function) is non-differentiable, which prevents standard backpropagation. To overcome this, we employ the **Straight-Through Estimator (STE)**. Our implementation of STE relies on a dual-path forward pass:\n",
        "\n",
        "1.  **The Binary Forward Pass (For Inference):** This is the \"true\" computation. It takes the underlying full-precision weights, binarizes them to strict `{-1, 1}` values, and performs the matrix multiplication. The resulting activations are also binarized. This path is used to get the model's actual output.\n",
        "\n",
        "2.  **The Continuous Forward Pass (For Gradients):** This is a \"proxy\" path used only for calculating gradients. Instead of a hard binarization, we use the `tanh()` function as a smooth, differentiable approximation. We apply `tanh()` to both the latent weights and the pre-activations. The gradients from this continuous path will serve as an estimate for the non-differentiable binary path.\n",
        "\n",
        "The `stop_gradient` function is the key that allows us to combine these two paths. In essence, during the forward pass, we compute the true binary output. During the backward pass, JAX computes gradients as if the forward pass had been the continuous `tanh`-based version.\n",
        "\n",
        "To ensure stable training from the start, we initialize the latent, full-precision weights using **He initialization**, a standard practice for deep networks."
      ],
      "metadata": {
        "id": "A0RvMjD2PtDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryLinear() :\n",
        "  def __init__(self, in_dim, out_dim) :\n",
        "    self.in_dim = in_dim\n",
        "    self.out_dim = out_dim\n",
        "    self.init_std = (2/self.in_dim)**(1/2)\n",
        "\n",
        "  def get_parameters(self) :\n",
        "    temp_params = np.random.randn(self.in_dim, self.out_dim)*self.init_std\n",
        "    temp_params = jnp.array(temp_params)\n",
        "\n",
        "    return temp_params\n",
        "\n",
        "  @staticmethod\n",
        "  def binarize_params(parameters) :\n",
        "    binary_params = jnp.tanh(parameters)\n",
        "    binary_params = binary_params > 0\n",
        "    binary_params = (binary_params*2) - 1\n",
        "\n",
        "    return binary_params\n",
        "\n",
        "  @staticmethod\n",
        "  def full_cont_forward(parameters, x) :\n",
        "    binary_params_cont = jnp.tanh(parameters)\n",
        "    act_now = jnp.tanh(x @ binary_params_cont)\n",
        "\n",
        "    return act_now\n",
        "\n",
        "  @staticmethod\n",
        "  def binary_forward(binary_parameters, x) :\n",
        "    out_now = jnp.tanh(x @ binary_parameters)\n",
        "    return (out_now > 0)*2-1\n",
        "\n",
        "  @staticmethod\n",
        "  def forward(parameters,  x) :\n",
        "    binary_params = BinaryLinear.binarize_params(parameters)\n",
        "    out_now = BinaryLinear.binary_forward(binary_params, x)\n",
        "\n",
        "    act_now = BinaryLinear.full_cont_forward(parameters, x)\n",
        "    # straight through estimator\n",
        "    out_now = out_now + act_now - stop_gradient(act_now)\n",
        "\n",
        "    return out_now"
      ],
      "metadata": {
        "id": "uOf-BKNbHlH0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assembling the Full Binary MLP\n",
        "\n",
        "With our `BinaryLinear` layer defined, we have the fundamental building block of our network. We can now construct a complete multi-layer perceptron (MLP) simply by stacking these layers. The output of each binary layer serves as the input to the next, allowing us to seamlessly extend the architecture to the desired depth."
      ],
      "metadata": {
        "id": "NKWDHNqeSXf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BinaryModel() :\n",
        "  def __init__(self, in_dim, hidden_dim, out_dim, num_hidden_layers = 1) :\n",
        "    self.in_dim = in_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.out_dim = out_dim\n",
        "    self.num_hidden_layers = num_hidden_layers\n",
        "\n",
        "\n",
        "  def get_parameters(self) :\n",
        "    params = [BinaryLinear(self.in_dim, self.hidden_dim).get_parameters()]\n",
        "    for i in range(self.num_hidden_layers) :\n",
        "      params.append(BinaryLinear(self.hidden_dim, self.hidden_dim).get_parameters())\n",
        "    params.append(BinaryLinear(self.hidden_dim, self.out_dim).get_parameters())\n",
        "\n",
        "    return params\n",
        "\n",
        "  @staticmethod\n",
        "  def binarize_params(parameters) :\n",
        "    binary_params = [BinaryLinear.binarize_params(param) for param in parameters]\n",
        "    return binary_params\n",
        "\n",
        "  @staticmethod\n",
        "  def binary_forward(binary_parameters, x) :\n",
        "    out_now = x\n",
        "    for param_now in binary_parameters :\n",
        "      out_now = BinaryLinear.binary_forward(param_now, out_now)\n",
        "\n",
        "    return out_now\n",
        "\n",
        "  @staticmethod\n",
        "  def forward(parameters,  x) :\n",
        "    out_now = x\n",
        "    for param_now in parameters :\n",
        "      out_now = BinaryLinear.forward(param_now, out_now)\n",
        "\n",
        "    return out_now"
      ],
      "metadata": {
        "id": "1FQ9psCkqsDF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function\n",
        "\n",
        "To train the network, we need a way to measure the difference between the model's predictions and the actual labels. For this multi-class classification task, we use the standard **cross-entropy loss**.\n",
        "\n",
        "Since the final layer of our network outputs raw scores (logits), we first apply a **softmax function** to convert these scores into a valid probability distribution across the 10 classes. The cross-entropy loss then quantifies how well this predicted probability distribution matches the true label."
      ],
      "metadata": {
        "id": "CGm2o5uOTP-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jnp_softmax(x, dim = -1) :\n",
        "  exp_x = jnp.exp(x)\n",
        "  exp_x = exp_x/jnp.sum(exp_x, dim, keepdims=True)\n",
        "  return exp_x"
      ],
      "metadata": {
        "id": "q2GTDvmrQV_e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(parameters, data_x, data_y) :\n",
        "  yhat = BinaryModel.forward(parameters, data_x)\n",
        "  prediction = jnp_softmax(yhat)\n",
        "\n",
        "  loss = -jnp.log(prediction[np.arange(len(data_x)), data_y])\n",
        "  loss = jnp.mean(loss)\n",
        "\n",
        "  return loss\n",
        "\n",
        "compute_grad_loss = jax.value_and_grad(compute_loss)\n",
        "compute_grad_loss = jax.jit(compute_grad_loss)"
      ],
      "metadata": {
        "id": "HW6dEWkbOfIR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Network\n",
        "\n",
        "We are now ready to train the model. Our architecture is a **Binary MLP** with two hidden layers, each containing 512 neurons. This network is designed to take a flattened, binarized MNIST image as input and produce a 10-dimensional output vector representing the scores for each digit (0-9).\n",
        "\n",
        "To optimize the network's latent (full-precision) parameters, we will use the **Adam optimizer**, a robust adaptive learning rate algorithm, implemented using the **Optax** library. We'll train the model on mini-batches of data for a set number of iterations, periodically evaluating its accuracy on the test set to monitor progress."
      ],
      "metadata": {
        "id": "h52goiaJTpPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BinaryModel(28*28,512,10,2)\n",
        "start_learning_rate = 3e-4\n",
        "optimizer = optax.adam(start_learning_rate)\n",
        "\n",
        "# Initialize parameters of the model + optimizer.\n",
        "params = model.get_parameters()\n",
        "opt_state = optimizer.init(params)"
      ],
      "metadata": {
        "id": "XiDmIUT3I5jZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_itr = 5000\n",
        "batch_size = 512\n",
        "\n",
        "for i in range(num_itr) :\n",
        "  rand_data = np.random.randint(0, len(x_train), batch_size)\n",
        "  x_now = x_train[rand_data]\n",
        "  y_now = y_train[rand_data]\n",
        "\n",
        "\n",
        "  value, grads = compute_grad_loss(params, x_now, y_now)\n",
        "  updates, opt_state = optimizer.update(grads, opt_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "\n",
        "  if i % 250 == 0 :\n",
        "    print(i, value, grads[0].sum(), params[0].sum())\n",
        "\n",
        "    num_data = 10000\n",
        "    yhat_test = model.binary_forward(model.binarize_params(params), x_test[0:num_data])\n",
        "    acc_now = np.mean(yhat_test.argmax(-1) == y_test[0:num_data])\n",
        "    print(\"ACCURACY:\", acc_now)\n",
        "\n",
        "yhat_test = model.binary_forward(model.binarize_params(params), x_test[0:num_data])\n",
        "acc_now = np.mean(yhat_test.argmax(-1) == y_test[0:num_data])\n",
        "print(\"ACCURACY:\", acc_now)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ockZyck-RgMb",
        "outputId": "ce14112f-1414-4afa-83a9-ab4c7567bcbd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 2.7289264 -5.5207934 31.925497\n",
            "ACCURACY: 0.1267\n",
            "250 1.0726473 -0.8413658 3.5015996\n",
            "ACCURACY: 0.8134\n",
            "500 0.98680985 11.956423 12.326802\n",
            "ACCURACY: 0.88009995\n",
            "750 0.92737806 -4.7224736 2.4974375\n",
            "ACCURACY: 0.8943\n",
            "1000 0.9149725 5.777484 15.63731\n",
            "ACCURACY: 0.9083\n",
            "1250 0.8944127 4.981589 12.1899805\n",
            "ACCURACY: 0.9184\n",
            "1500 0.91286755 1.9172374 13.0103445\n",
            "ACCURACY: 0.9187\n",
            "1750 0.8621817 -1.9354597 1.457814\n",
            "ACCURACY: 0.937\n",
            "2000 0.870172 -0.2024888 16.750154\n",
            "ACCURACY: 0.9388\n",
            "2250 0.8579543 5.9929247 18.360256\n",
            "ACCURACY: 0.93659997\n",
            "2500 0.85207164 -3.8809388 10.52321\n",
            "ACCURACY: 0.9411\n",
            "2750 0.8484864 2.0417485 30.328266\n",
            "ACCURACY: 0.9429\n",
            "3000 0.85372627 3.1673765 25.864372\n",
            "ACCURACY: 0.94939995\n",
            "3250 0.8898465 -5.752628 25.04128\n",
            "ACCURACY: 0.94369996\n",
            "3500 0.83574003 2.9791057 10.119284\n",
            "ACCURACY: 0.94879997\n",
            "3750 0.8424428 -2.888378 12.361624\n",
            "ACCURACY: 0.9554\n",
            "4000 0.8423771 0.8031699 19.783243\n",
            "ACCURACY: 0.94909996\n",
            "4250 0.8234898 0.15095502 36.644356\n",
            "ACCURACY: 0.9478\n",
            "4500 0.84210366 -5.8466005 29.090614\n",
            "ACCURACY: 0.95589995\n",
            "4750 0.83429223 -5.910996 18.036402\n",
            "ACCURACY: 0.954\n",
            "ACCURACY: 0.9539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_data = 10000\n",
        "yhat = model.binary_forward(model.binarize_params(params), x_test[0:num_data])\n",
        "acc_now = np.mean(yhat.argmax(-1) == y_test[0:num_data])\n",
        "print(\"ACCURACY:\", acc_now)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_p3aE0OBUUv",
        "outputId": "c9005920-bde1-48bd-db79-db88bcb4f94e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY: 0.9539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking The Binary Parameters"
      ],
      "metadata": {
        "id": "kUB2z12cUJCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.binarize_params(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0C5SqIvFDlU",
        "outputId": "e89e8fb7-7aca-4981-ee6c-b5f1b3f78af3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Array([[-1,  1, -1, ...,  1,  1, -1],\n",
              "        [ 1,  1,  1, ..., -1, -1,  1],\n",
              "        [-1,  1, -1, ..., -1,  1,  1],\n",
              "        ...,\n",
              "        [ 1,  1,  1, ...,  1,  1, -1],\n",
              "        [-1, -1,  1, ..., -1,  1, -1],\n",
              "        [ 1, -1,  1, ...,  1,  1, -1]], dtype=int32, weak_type=True),\n",
              " Array([[ 1, -1, -1, ...,  1, -1, -1],\n",
              "        [ 1, -1,  1, ..., -1, -1,  1],\n",
              "        [-1,  1, -1, ...,  1, -1,  1],\n",
              "        ...,\n",
              "        [ 1, -1,  1, ..., -1,  1, -1],\n",
              "        [ 1,  1, -1, ...,  1, -1,  1],\n",
              "        [ 1,  1, -1, ...,  1,  1, -1]], dtype=int32, weak_type=True),\n",
              " Array([[-1,  1, -1, ...,  1,  1, -1],\n",
              "        [ 1, -1,  1, ...,  1, -1, -1],\n",
              "        [-1,  1, -1, ...,  1,  1,  1],\n",
              "        ...,\n",
              "        [ 1, -1, -1, ...,  1,  1,  1],\n",
              "        [ 1,  1,  1, ...,  1, -1, -1],\n",
              "        [ 1, -1,  1, ..., -1, -1,  1]], dtype=int32, weak_type=True),\n",
              " Array([[ 1,  1, -1, ..., -1,  1,  1],\n",
              "        [ 1,  1,  1, ...,  1, -1,  1],\n",
              "        [ 1,  1, -1, ...,  1, -1,  1],\n",
              "        ...,\n",
              "        [ 1,  1,  1, ...,  1,  1,  1],\n",
              "        [-1,  1,  1, ...,  1,  1, -1],\n",
              "        [ 1, -1, -1, ..., -1,  1,  1]], dtype=int32, weak_type=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "We have successfully trained a multi-layer perceptron on the MNIST dataset where both the weights and activations are fully binary. While MNIST is a relatively simple benchmark, this project serves as a clear proof-of-concept, demonstrating that it is possible to train these highly constrained networks from scratch using the Straight-Through Estimator.\n",
        "\n",
        "Our simple binary MLP achieved an accuracy of approximately **95%**. This is a noteworthy result, validating that even with such extreme quantization, the model can learn meaningful representations. However, it's important to place this in context: a significant performance gap remains when compared to standard full-precision MLPs or more sophisticated binary network architectures, which routinely achieve accuracies exceeding 98-99% on this task.\n",
        "\n",
        "Ultimately, this experiment highlights the immense potential of binary neural networks. Their dramatically reduced memory footprint and the ability to replace expensive floating-point multiplications with efficient bitwise operations make them a compelling solution for deploying AI on resource-constrained hardware, such as IoT devices and edge sensors. This work lays the groundwork for exploring more advanced binary architectures and tackling more complex problems in the future."
      ],
      "metadata": {
        "id": "yLfzcQ7kVkE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "\n",
        "*   Jax Documentation, https://docs.jax.dev/en/latest/\n",
        "*   Optax Documentation, https://optax.readthedocs.io/\n",
        "*   Original Binary NN, https://arxiv.org/pdf/1602.02830\n",
        "*   Straight-Throught Estimator, https://arxiv.org/abs/1308.3432\n",
        "*   Adam Optimizer, https://arxiv.org/abs/1412.6980\n",
        "\n"
      ],
      "metadata": {
        "id": "y3xtZHMwWUvz"
      }
    }
  ]
}